{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the project by importing the necessary libraries and modules. Additionally, we load the dataset and clean it by utilizing only the initially identified features and dropping rows with null values. Furthermore, we merge the features 'Members with age less than 5 years old' and 'Members with age 5 - 17 years old' to create the 'Number of Children' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = ['Housing and water Expenditure', 'Total Household Income', 'Region', 'Agricultural Household indicator', 'Imputed House Rental Value', 'Total Income from Entrepreneurial Acitivites', 'Total Number of Family members', 'Members with age less than 5 year old', 'Members with age 5 - 17 years old', 'Total number of family members employed', 'Type of Building/House', 'Type of Roof', 'Type of Walls', 'House Floor Area', 'House Age', 'Number of bedrooms', 'Electricity', 'Main Source of Water Supply', 'Number of Television', 'Number of CD/VCD/DVD', 'Number of Component/Stereo set', 'Number of Refrigerator/Freezer', 'Number of Washing Machine', 'Number of Airconditioner', 'Number of Personal Computer']\n",
    "# a = [22170, 133060, 'CAR', 0, 11400, 14150, 6, 0, 0, 2, 'Single house', 'Strong material(galvanized,iron,al,tile,concrete,brick,stone,asbestos)', 'Strong', 18, 5, 0, 1, 'Protected spring, river, stream, etc', 1, 0, 0, 0, 0, 0, 0]\n",
    "# b = [50736, 311450, 'CAR', 0, 36000, 221300, 1, 0, 0, 0, 'Single house', 'Strong material(galvanized,iron,al,tile,concrete,brick,stone,asbestos)', 'Strong', 100, 33, 2, 1, 'Own use, tubed/piped deep well', 1, 0, 0, 1, 0, 0, 0]\n",
    "# c = [10956, 72914, 'CAR', 0, 6000, 1500, 6, 0, 4, 2, 'Single house', 'Strong material(galvanized,iron,al,tile,concrete,brick,stone,asbestos)', 'Quite Strong', 20, 35, 0, 1, 'Own use, tubed/piped deep well', 1, 0, 0, 0, 0, 0, 0]\n",
    "# d = [44370, 179542, 'CAR', 1, 36000, 94944, 7, 1, 0, 1, 'Single house', 'Strong material(galvanized,iron,al,tile,concrete,brick,stone,asbestos)', 'Strong', 40, 25, 1, 1, 'Protected spring, river, stream, etc', 1, 1, 0, 0, 0, 0, 1]\n",
    "# e = [8412, 111003, 'CAR', 1, 2250, 45305, 9, 0, 4, 2, 'Single house', 'Strong material(galvanized,iron,al,tile,concrete,brick,stone,asbestos)', 'Strong', 100, 38, 4, 1, 'Protected spring, river, stream, etc', 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# indices_to_remove = [3, 5, 7, 8, 9, 11, 12, 16, 18]  # Indices of elements to remove\n",
    "\n",
    "# # Remove elements from each list using a for loop\n",
    "# for index in sorted(indices_to_remove, reverse=True):\n",
    "#     for lst in [z, a, b, c, d, e]:\n",
    "#         del lst[index]\n",
    "\n",
    "# print(z)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(c)\n",
    "# print(d)\n",
    "# print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "\n",
    "df_dataset = pd.read_csv('Family Income and Expenditure.csv')\n",
    "\n",
    "# Initial features to use\n",
    "features = [\n",
    "    \"Housing and water Expenditure\",\n",
    "    \"Total Household Income\",\n",
    "    \"Region\",\n",
    "    \"Agricultural Household indicator\",\n",
    "    \"Imputed House Rental Value\",\n",
    "    \"Total Income from Entrepreneurial Acitivites\",\n",
    "    \"Total Number of Family members\",\n",
    "    \"Members with age less than 5 year old\",\n",
    "    \"Members with age 5 - 17 years old\",\n",
    "    \"Total number of family members employed\",\n",
    "    \"Type of Building/House\",\n",
    "    \"Type of Roof\",\n",
    "    \"Type of Walls\",\n",
    "    \"House Floor Area\",\n",
    "    \"House Age\",\n",
    "    \"Number of bedrooms\",\n",
    "    \"Electricity\",\n",
    "    \"Main Source of Water Supply\",\n",
    "    \"Number of Television\",\n",
    "    \"Number of CD/VCD/DVD\",\n",
    "    \"Number of Component/Stereo set\",\n",
    "    \"Number of Refrigerator/Freezer\",\n",
    "    \"Number of Washing Machine\",\n",
    "    \"Number of Airconditioner\",\n",
    "    \"Number of Personal Computer\"\n",
    "]\n",
    "\n",
    "df_temp = df_dataset.filter(features, axis=1)\n",
    "\n",
    "df_temp.dropna(inplace=True)\n",
    "\n",
    "# Assuming your dataset is stored in a pandas DataFrame called 'df'\n",
    "sample_rows = df_temp[df_temp['Region'] == 'CAR'].sample(n=5)\n",
    "\n",
    "# Convert each row into a list\n",
    "sample_rows_list = sample_rows.values.tolist()\n",
    "\n",
    "# Print the feature names\n",
    "print(sample_rows.columns.tolist())\n",
    "\n",
    "# Print the sample rows as lists\n",
    "for row in sample_rows_list:\n",
    "    print(row)\n",
    "\n",
    "df_temp['Number of Children'] = df_temp['Members with age less than 5 year old'] + df_temp['Members with age 5 - 17 years old']\n",
    "\n",
    "df_temp = df_temp.drop(['Members with age less than 5 year old', 'Members with age 5 - 17 years old'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will identify the list of unique categories for three categorical features: Region, Type of Building/House, and Main Source of Water Supply. Note that this step is necessary since, as we will see later, these three features are included in the final Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = list(df_temp['Region'].unique())\n",
    "print(f'Regions: {region_names}') # output: ['CAR', 'Caraga', 'VI - Western Visayas', 'V - Bicol Region', ' ARMM', 'III - Central Luzon', 'II - Cagayan Valley', 'IVA - CALABARZON', 'VII - Central Visayas', 'X - Northern Mindanao', 'XI - Davao Region', 'VIII - Eastern Visayas', 'I - Ilocos Region', 'NCR', 'IVB - MIMAROPA', 'XII - SOCCSKSARGEN', 'IX - Zasmboanga Peninsula']\n",
    "\n",
    "house_types = list(df_temp['Type of Building/House'].unique())\n",
    "print(f'Type of Building/House: {house_types}') # output : ['Single house', 'Duplex', 'Commercial/industrial/agricultural building', 'Multi-unit residential', 'Institutional living quarter', 'Other building unit (e.g. cave, boat)']\n",
    "\n",
    "water_sources = list(df_temp['Main Source of Water Supply'].unique())\n",
    "print(f'Main Source of Water Supply: {water_sources}') # output : ['Own use, faucet, community water system', 'Shared, faucet, community water system', 'Shared, tubed/piped deep well', 'Own use, tubed/piped deep well', 'Protected spring, river, stream, etc', 'Tubed/piped shallow well', 'Lake, river, rain and others', 'Unprotected spring, river, stream, etc', 'Dug well', 'Others', 'Peddler']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection, we can see two typographical errors. These errors are the ' ARMM' and 'IX - Zasmboanga Peninsula' categories of the Region feature. We will correct them using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct typos in region names\n",
    "df_temp['Region'] = df_temp['Region'].replace(' ARMM', 'ARMM')\n",
    "df_temp['Region'] = df_temp['Region'].replace('IX - Zasmboanga Peninsula', 'IX - Zamboanga Peninsula')\n",
    "\n",
    "# update region names\n",
    "region_names = list(df_temp['Region'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have categorical variables, we use target encoding to convert categorical values into numerical ones. We also store the encoding map for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical columns\n",
    "cat_cols = ['Region', 'Type of Building/House', 'Type of Roof', 'Type of Walls', 'Main Source of Water Supply']\n",
    "\n",
    "# Create an instance of the TargetEncoder\n",
    "encoder = ce.TargetEncoder(cols=cat_cols)\n",
    "\n",
    "# Fit and transform the target encoder on the dataframe\n",
    "df_encoded = encoder.fit_transform(df_temp, df_temp['Housing and water Expenditure'])\n",
    "\n",
    "# Access the mapping\n",
    "mapping = encoder.mapping\n",
    "\n",
    "# Replace the original categorical columns with the target-encoded values\n",
    "df_temp[cat_cols] = df_encoded[cat_cols]\n",
    "\n",
    "# Create a dictionary mapping the categorical columns to the target encoding\n",
    "cat_dict_map = {}\n",
    "for column in cat_cols:\n",
    "    cat_dict_map[column] = list(mapping[column])[:-2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the encoding map, we create dictionaries for converting the categorical features included in the final regression model. To avoid confusion, we note that these features are identified by the feature selection method, which will be performed later on. Essentially, we added these codes to this part because we already know that they will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_region = {k: v for k, v in zip(region_names, cat_dict_map['Region'])}\n",
    "convert_house_type = {k: v for k, v in zip(house_types, cat_dict_map['Type of Building/House'])}\n",
    "convert_water_source = {k: v for k, v in zip(water_sources, cat_dict_map['Main Source of Water Supply'])}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to begin building our regression model. We start by separating the features from the target, which is 'Housing and Water Expenditure'. Then, we determine highly correlated features and drop them. However, we can see that the initial features are not highly correlated. Thus, no features are dropped at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_temp.drop(['Housing and water Expenditure'], axis=1)\n",
    "y = df_temp['Housing and water Expenditure']\n",
    "\n",
    "# Correlation Matrix\n",
    "threshold = 0.9\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "upper.head()\n",
    "\n",
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "if len(to_drop) > 0:\n",
    "    print(f'Columns to drop: {to_drop}')\n",
    "    X = X.drop(to_drop, axis=1)\n",
    "else:\n",
    "    print('No columns to drop. The features are not highly correlated.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we determine the best features to use in the regression model. We split our data for training and testing. Additionally, we observe that a linear regression model was used for sequential feature selection. This is because it is the simplest regression model, and feature selection requires a significant amount of computation power and time. We drop the features that are not selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Forward feature selection\n",
    "regressor = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(regressor, k_features='best', forward=True, scoring='neg_mean_squared_error', cv=5)\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "selected_features = list(X_train.columns[list(sfs.k_feature_idx_)])\n",
    "print(f'Selected Features: {selected_features}')\n",
    "\n",
    "# Drop features that are not selected\n",
    "to_drop = [feature for feature in X.columns if feature not in selected_features]\n",
    "X = X.drop(to_drop, axis=1)\n",
    "print(f'Dropped features: {to_drop}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we account for interactions between the features. In particular, we model these interactions as a second-degree polynomial. Apart from saving computational resources, using this degree yields the best results compared to using higher degrees. This can be explained by factors such as overfitting. We also split the data again for the training and testing of our Polynomial Regression model. Observe that it now uses X_interactions, which account for the feature interactions, instead of the original data X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLYNOMIAL\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interactions = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interactions, y, test_size=0.30, random_state=1)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we assess the metrics, such as RMSE and R2. We can see that our Polynomial Regression model has an R2 close to 1 and a relatively low RMSE, indicating that it performs well in predicting the target. Note that although the RMSE is in the thousands, its unit is the Philippine Peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show and plot the results\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predicted vs Target')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make a locally-hosted Web App that predicts the Housing and Water expenditures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(input_arr):\n",
    "    encoded_input = [input_arr]\n",
    "\n",
    "    for i in range(len(input_arr)):\n",
    "        if i == 1:\n",
    "            encoded_input[0][i] = convert_region[input_arr[i]]\n",
    "        elif i == 4:\n",
    "            encoded_input[0][i] = convert_house_type[input_arr[i]]\n",
    "        elif i == 8:\n",
    "            encoded_input[0][i] = convert_water_source[input_arr[i]] \n",
    "\n",
    "    # Perform polynomial feature transformation if applicable\n",
    "    input_interactions = poly.fit_transform(encoded_input)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = regressor.predict(input_interactions)\n",
    "\n",
    "    return float(prediction[0])\n",
    "\n",
    "# input_arr = [111003, 'CAR', 2250, 9, 'Single house', 100, 38, 4, 'Protected spring, river, stream, etc', 0, 0, 0, 0, 0, 0]\n",
    "# result = model_predict(input_arr)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "\n",
    "# Change based on Saved location\n",
    "path = r'C:\\Users\\Brylle\\Desktop\\CS180-Project\\templates'\n",
    "\n",
    "app = Flask(__name__, static_folder = path)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Flask route handler\n",
    "@app.route('/calculate', methods=['POST'])\n",
    "def calculate():\n",
    "    features = [key for key in request.form.keys() if key.startswith('input')]\n",
    "    input_arr = [request.form.get(key) for key in features]\n",
    "    conv_input = [float(input_arr[i]) if i not in (1,4,8) else input_arr[i] for i in range(len(input_arr))]\n",
    "    result = round(model_predict(conv_input), 2)\n",
    "    return jsonify(result=result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
