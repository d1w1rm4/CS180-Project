{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the project by importing the necessary libraries and modules. Additionally, we load the dataset and clean it by utilizing only the initially identified features and dropping rows with null values. Furthermore, we merge the features 'Members with age less than 5 years old' and 'Members with age 5 - 17 years old' to create the 'Number of Children' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Load the dataset\n",
    "df_dataset = pd.read_csv('Family Income and Expenditure.csv')\n",
    "\n",
    "# Initial features to use\n",
    "features = [\n",
    "    \"Housing and water Expenditure\",\n",
    "    \"Total Household Income\", #1\n",
    "    \"Region\", #2\n",
    "    \"Agricultural Household indicator\", #3\n",
    "    \"Imputed House Rental Value\", #4\n",
    "    \"Total Income from Entrepreneurial Acitivites\", #5\n",
    "    \"Total Number of Family members\", #6\n",
    "    \"Members with age less than 5 year old\", #7\n",
    "    \"Members with age 5 - 17 years old\",#8\n",
    "    \"Total number of family members employed\", #9\n",
    "    \"Type of Building/House\", #10\n",
    "    \"Type of Roof\",\n",
    "    \"Type of Walls\",\n",
    "    \"House Floor Area\",\n",
    "    \"House Age\",\n",
    "    \"Number of bedrooms\",\n",
    "    \"Electricity\",\n",
    "    \"Main Source of Water Supply\",\n",
    "    \"Number of Television\",\n",
    "    \"Number of CD/VCD/DVD\",\n",
    "    \"Number of Component/Stereo set\",\n",
    "    \"Number of Refrigerator/Freezer\",\n",
    "    \"Number of Washing Machine\",\n",
    "    \"Number of Airconditioner\",\n",
    "    \"Number of Personal Computer\"\n",
    "]\n",
    "\n",
    "# Drop features that are not in the initial set of features\n",
    "df = df_dataset.filter(features, axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Create feature called \"Number of Children\"\n",
    "df['Number of Children'] = df['Members with age less than 5 year old'] + df['Members with age 5 - 17 years old']\n",
    "\n",
    "# Drop combined features\n",
    "df = df.drop(['Members with age less than 5 year old', 'Members with age 5 - 17 years old'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will identify the list of unique categories for three categorical features: Region, Type of Building/House, and Main Source of Water Supply. Note that this step is necessary since, as we will see later, these three features are included in the final Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique values for each of the three categorical feature included in the final regression model\n",
    "\n",
    "# list region names\n",
    "region_names = list(df['Region'].unique())\n",
    "print(f'Regions: {region_names}') # output: ['CAR', 'Caraga', 'VI - Western Visayas', 'V - Bicol Region', ' ARMM', 'III - Central Luzon', 'II - Cagayan Valley', 'IVA - CALABARZON', 'VII - Central Visayas', 'X - Northern Mindanao', 'XI - Davao Region', 'VIII - Eastern Visayas', 'I - Ilocos Region', 'NCR', 'IVB - MIMAROPA', 'XII - SOCCSKSARGEN', 'IX - Zasmboanga Peninsula']\n",
    "\n",
    "# list type of building/house\n",
    "house_types = list(df['Type of Building/House'].unique())\n",
    "print(f'Type of Building/House: {house_types}') # output : ['Single house', 'Duplex', 'Commercial/industrial/agricultural building', 'Multi-unit residential', 'Institutional living quarter', 'Other building unit (e.g. cave, boat)']\n",
    "\n",
    "# list main source of water supply\n",
    "water_sources = list(df['Main Source of Water Supply'].unique())\n",
    "print(f'Main Source of Water Supply: {water_sources}') # output : ['Own use, faucet, community water system', 'Shared, faucet, community water system', 'Shared, tubed/piped deep well', 'Own use, tubed/piped deep well', 'Protected spring, river, stream, etc', 'Tubed/piped shallow well', 'Lake, river, rain and others', 'Unprotected spring, river, stream, etc', 'Dug well', 'Others', 'Peddler']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection, we can see two typographical errors. These errors are the ' ARMM' and 'IX - Zasmboanga Peninsula' categories of the Region feature. We will correct them using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct typos in region names\n",
    "df['Region'] = df['Region'].replace(' ARMM', 'ARMM')\n",
    "df['Region'] = df['Region'].replace('IX - Zasmboanga Peninsula', 'IX - Zamboanga Peninsula')\n",
    "\n",
    "# Update region names\n",
    "region_names = list(df['Region'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have categorical variables, we use target encoding to convert categorical values into numerical ones. We also store the encoding map for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical columns\n",
    "cat_cols = ['Region', 'Type of Building/House', 'Type of Roof', 'Type of Walls', 'Main Source of Water Supply']\n",
    "\n",
    "# Create an instance of the TargetEncoder\n",
    "encoder = ce.TargetEncoder(cols=cat_cols)\n",
    "\n",
    "# Fit and transform the target encoder on the dataframe\n",
    "df_encoded = encoder.fit_transform(df, df['Housing and water Expenditure'])\n",
    "\n",
    "# Access the mapping\n",
    "mapping = encoder.mapping\n",
    "\n",
    "# Replace the original categorical columns with the target-encoded values\n",
    "df[cat_cols] = df_encoded[cat_cols]\n",
    "\n",
    "# Create a dictionary mapping the categorical columns to the target encoding\n",
    "cat_dict_map = {}\n",
    "for column in cat_cols:\n",
    "    cat_dict_map[column] = list(mapping[column])[:-2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the encoding map, we create dictionaries for converting the categorical features included in the final regression model. To avoid confusion, we note that these features are identified by the feature selection method, which will be performed later on. Essentially, we added these codes to this part because we already know that they will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping the categorical columns to the target encoding\n",
    "\n",
    "convert_region = {k: v for k, v in zip(region_names, cat_dict_map['Region'])}\n",
    "convert_house_type = {k: v for k, v in zip(house_types, cat_dict_map['Type of Building/House'])}\n",
    "convert_water_source = {k: v for k, v in zip(water_sources, cat_dict_map['Main Source of Water Supply'])}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to begin building our regression model. We start by separating the features from the target, which is 'Housing and Water Expenditure'. Then, we determine highly correlated features and drop them. However, we can see that the initial features are not highly correlated. Thus, no features are dropped at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into X and y\n",
    "X = df.drop(['Housing and water Expenditure'], axis=1)\n",
    "y = df['Housing and water Expenditure']\n",
    "\n",
    "# Analyze the correlation among the features\n",
    "threshold = 0.9\n",
    "corr_matrix = X.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "upper.head()\n",
    "\n",
    "# Drop columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "if len(to_drop) > 0:\n",
    "    print(f'Columns to drop: {to_drop}')\n",
    "    X = X.drop(to_drop, axis=1)\n",
    "else:\n",
    "    print('No columns to drop. The features are not highly correlated.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we determine the best features to use in the regression model. We split our data for training and testing. Additionally, we observe that a linear regression model was used for sequential feature selection. This is because it is the simplest regression model, and feature selection requires a significant amount of computation power and time. We drop the features that are not selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Forward feature selection\n",
    "regressor = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(regressor, k_features='best', forward=True, scoring='neg_mean_squared_error', cv=5)\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "selected_features = list(X_train.columns[list(sfs.k_feature_idx_)])\n",
    "print(f'Selected Features: {selected_features}')\n",
    "\n",
    "# Drop features that are not selected\n",
    "to_drop = [feature for feature in X.columns if feature not in selected_features]\n",
    "X = X.drop(to_drop, axis=1)\n",
    "print(f'Dropped features: {to_drop}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we account for interactions between the features. In particular, we model these interactions as a second-degree polynomial. Apart from saving computational resources, using this degree yields the best results compared to using higher degrees. This can be explained by factors such as overfitting. We also split the data again for the training and testing of our Polynomial Regression model. Observe that it now uses X_interactions, which account for the feature interactions, instead of the original data X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interactions = poly.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets using X_interactions instead of X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interactions, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Fit the model and predict the target\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we assess the metrics, such as RMSE and R2. We can see that our Polynomial Regression model has an R2 close to 1 and a relatively low RMSE, indicating that it performs well in predicting the target. Note that although the RMSE is in the thousands, its unit is the Philippine Peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show and plot the results\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predicted vs Target')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Flask, we now make a locally-hosted Web App that predicts the Housing and Water expenditures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to predict the Housing and Water expenditure given an array of user inputs\n",
    "def model_predict(input_arr):\n",
    "    encoded_input = [input_arr]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    for i in range(len(input_arr)):\n",
    "        if i == 1:\n",
    "            encoded_input[0][i] = convert_region[input_arr[i]]\n",
    "        elif i == 4:\n",
    "            encoded_input[0][i] = convert_house_type[input_arr[i]]\n",
    "        elif i == 8:\n",
    "            encoded_input[0][i] = convert_water_source[input_arr[i]] \n",
    "\n",
    "    # Perform polynomial feature transformation if applicable\n",
    "    input_interactions = poly.fit_transform(encoded_input)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = regressor.predict(input_interactions)\n",
    "\n",
    "    # Return prediction\n",
    "    return float(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "\n",
    "# Change based on Saved location\n",
    "path = r'C:\\Users\\Brylle\\Desktop\\CS180-Project'\n",
    "\n",
    "app = Flask(__name__, static_folder = path)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Flask route handler\n",
    "@app.route('/calculate', methods=['POST'])\n",
    "def calculate():\n",
    "    features = [key for key in request.form.keys() if key.startswith('input')]\n",
    "    input_arr = [request.form.get(key) for key in features]\n",
    "    conv_input = [float(input_arr[i]) if i not in (1,4,8) else input_arr[i] for i in range(len(input_arr))]\n",
    "    result = 'Php'+str(round(model_predict(conv_input), 2))\n",
    "    return jsonify(result=result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
